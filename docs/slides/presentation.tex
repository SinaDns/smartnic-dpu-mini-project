\documentclass[10pt]{beamer}

% --- Theme and Colors ---
\usetheme{Madrid}
\usecolortheme{whale}

\setbeamercolor{block title}{bg=blue!70!black,fg=white}
\setbeamercolor{block body}{bg=blue!5!white,fg=black}
\setbeamerfont{title}{series=\bfseries,parent=structure}
\setbeamertemplate{navigation symbols}{} % Hide nav symbols

% --- Packages ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}

% --- Title Information ---
\title[SmartNICs \& DPUs]{SmartNICs and Data Processing Units (DPUs)}
\subtitle{Computer Networks}
\author[Daneshgar \& Abbaszadeh]{Sina Daneshgar \\ Mohammadmohsen Abbaszadeh}
\institute[Sharif Uni. of Tech.]{Sharif University of Technology}
\date[Feb 2026]{Feb 2026}

\begin{document}

% 1. Title Slide
\begin{frame}
    \titlepage
\end{frame}

% 2. Outline
\begin{frame}{Outline}
    \tableofcontents
\end{frame}

\section{Introduction and Global Context}
\begin{frame}{The Evolution of Compute}
    \begin{description}
        \item[CPU] General purpose, high flexibility, but high latency for simple repetitive tasks.
        \item[GPU] Specialized for parallel processing (Graphics, AI).
        \item[DPU] Specialized for \textbf{Data-Centric} tasks (Moving, Processing, Securing data).
    \end{description}
    \vfill
    \begin{block}{Why now?}
        Moore's Law is slowing down, while networking speeds are exploding (10G $\rightarrow$ 100G $\rightarrow$ 400G). The CPU can no longer keep up with the networking interrupt load.
    \end{block}
\end{frame}

\section{The Infrastructure Tax}
\begin{frame}{Quantifying the "Infrastructure Tax"}
    Data centers spend 20-30\% of their total compute power just on "tax" tasks:
    \begin{itemize}
        \item \textbf{Virtualization}: OVS (Open vSwitch) overhead, encapsulation (VXLAN, Geneve).
        \item \textbf{Storage}: NVMe-oF (NVMe over Fabrics) protocol translation and management.
        \item \textbf{Security}: Distributed Firewalls, Micro-segmentation, and Wire-speed TLS/IPsec.
    \end{itemize}
    \vfill
    \begin{alertblock}{The Bottleneck}
        Every packet processed by the CPU is a cycle stolen from the user application (Application Stall).
    \end{alertblock}
\end{frame}

\section{Detailed Architecture}
\begin{frame}{Deep Dive: What's inside a DPU?}
    Unlike a standard NIC, a DPU (like NVIDIA BlueField or AMD Pensando) contains:
    \begin{itemize}
        \item \textbf{ARM/RISC-V Cluster}: Runs a standard Linux OS for management and control.
        \item \textbf{Network Acceleration Engine}: Programmable hardware for parsing and switching.
        \item \textbf{Hardware Engines}:
            \begin{itemize}
                \item \textbf{Crypto}: Hardware-accelerated IPsec/TLS and Disk encryption.
                \item \textbf{Storage}: VirtIO-blk acceleration and Compression engines.
                \item \textbf{Timing}: PTP (Precision Time Protocol) for finance/telecom.
            \end{itemize}
        \item \textbf{On-board RAM}: For local state, lookups, and buffering (\approx16-32GB DDR4/5).
    \end{itemize}
\end{frame}

\begin{frame}{SmartNIC Landscape}
    \begin{center}
        \includegraphics[width=0.95\textwidth]{../../assets/smartNIC_landscape.png}
    \end{center}
    \vspace{2mm}
    \begin{itemize}
        \item Spectrum from fixed-function NICs to highly-programmable DPUs (compare programmability vs. capability).
        \item Comparing programmability versus throughput, latency, and power.
    \end{itemize}
\end{frame}

\section{Programming Paradigms}
\begin{frame}{Programmability: P4 and the Match-Action Pipeline}
    \begin{itemize}
        \item \textbf{P4 (Programming Protocol-independent Packet Processors)}:
            \begin{itemize}
                \item Define custom headers and parsers.
                \item Programmable Match-Action tables inside the NIC silicon.
                \item Allows for "Protocol Independence."
            \end{itemize}
        \item \textbf{Implementation}: See \texttt{examples/02-p4-programmability/basic\_l2.p4} -- a minimal L2 forwarding example (match-action table).
    \end{itemize}
\end{frame}

\begin{frame}{Programmability: eBPF and XDP}
    \begin{itemize}
        \item \textbf{eBPF (Extended Berkeley Packet Filter)}:
            \begin{itemize}
                \item Runs JIT-compiled bytecode inside the Linux kernel.
                \item High safety (verified at load time) and extreme speed.
            \end{itemize}
        \item \textbf{XDP (eXpress Data Path)}:
            \begin{itemize}
                \item An eBPF hook placed as early as possible (the NIC driver).
                \item Can DROP, FORWARD, or REDIRECT packets \textit{before} the kernel allocates a socket buffer (\texttt{sk\_buff}).
            \end{itemize}
        \item \textbf{Demo}: See \texttt{examples/03-ebpf-xdp/03-ebpf\_xdp.c} (ICMP-drop example).
    \end{itemize}
\end{frame}

\begin{frame}{eBPF / XDP: Runtime Architecture}
    \centering
    \includegraphics[width=0.85\textwidth]{../../assets/smartnic_workflow.png}
    \vspace{2mm}
    \begin{itemize}
        \item Kernel-level verification and JIT -- safe, high-speed packet processing.
        \item XDP attaches at the driver level (earliest path) -- ideal for filtering and DDoS mitigation.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Code: P4 -- basic L2}
\begin{lstlisting}[basicstyle=\ttfamily\small]
// action forward sets egress port based on dst MAC
action forward(bit<9> port) { meta.egress_spec = port; }

// table: exact-match on dst MAC -> forward / drop
table mac_forwarding {
    key = { hdr.ethernet.dstAddr: exact; }
    actions = { forward; drop; }
}
\end{lstlisting}
\begin{itemize}
    \item Simple match-action pipeline: lookups happen in hardware tables.
    \item See \texttt{examples/02-p4-programmability/basic\_l2.p4} to demonstrate how the control plane installs MAC \rightarrow port table entries.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Code: eBPF/XDP -- ICMP drop}
\begin{lstlisting}[language=C,basicstyle=\ttfamily\small]
if (ip->protocol == IPPROTO_ICMP) {
    // drop ICMP packets
    return XDP_DROP;
}
\end{lstlisting}
\begin{itemize}
    \item Early drop in kernel driver path -- zero-copy and minimal CPU.
    \item Attach with \texttt{ip link set dev <iface> xdp obj ...} (see file header).
\end{itemize}
\end{frame}

\section{Real-World Applications}
\begin{frame}{Application 1: Cloud Resource Disaggregation}
    \begin{itemize}
        \item \textbf{Traditional}: Storage and Compute locked in the same physical box.
        \item \textbf{DPU-based}: Storage is remote (over NVMe-oF), but the DPU makes it look like a local NVMe drive to the host OS.
    \end{itemize}
    \vfill
    \begin{exampleblock}{Benefit}
        For many workloads, NVMe-oF via a DPU can deliver performance close to a local SSD while providing the flexibility of network-attached storage.
    \end{exampleblock}
\end{frame}

\begin{frame}{Application 2: Bare Metal as a Service (BMaaS)}
    \begin{itemize}
        \item Cloud providers (AWS, Azure) want to rent "Bare Metal" to users.
        \item \textbf{Problem}: How to monitor and isolate the user if they have full control?
        \item \textbf{Solution}: The DPU acts as the "Sidecar" manager. It manages networking and security \textit{outside} the host, so the user cannot bypass it.
    \end{itemize}
\end{frame}

\begin{frame}{Application 3: Line-rate Security \& DDoS Mitigation}
    \begin{itemize}
        \item \textbf{Problem}: Volumetric attacks and high-rate malicious flows can saturate host CPUs and network queues.
        \item \textbf{DPU approach}: perform early-drop and per-flow state in the NIC (P4 / hardware match-action) or attach XDP/eBPF at the driver for rapid filtering.
        \item \textbf{Benefits}: drop malicious traffic at line-rate, reduce host CPU consumption, and enable real-time telemetry for upstream mitigation.
        \item \textbf{Demo hint}: run the XDP example in \texttt{examples/03-ebpf-xdp} to show early-drop; explain how production systems move similar logic onto DPUs.
    \end{itemize}
\end{frame}

\section{Performance Simulation}
\begin{frame}{Simulation: Offload Performance}
    We simulated the host CPU throughput gains when offloading work to a DPU.
    \vfill
    \centering
    \includegraphics[width=0.75\textwidth]{../../assets/offload_plot.png}
    \vspace{2mm}
    \small Model note: as the fraction $\alpha$ of packet processing is offloaded, host throughput improves roughly in proportion â€” until other bottlenecks (PCIe, NIC) appear.
    \vfill
    \par\footnotesize In our simulation, moving packet-processing logic to the hardware dataplane yielded more than a 50\% throughput improvement for the targeted workloads.
\end{frame}

\section{Summary and Future Outlook}
\begin{frame}{Current Challenges and Limitations}
    \begin{itemize}
        \item \textbf{Vendor Lock-in}: No universal "Standard" for all DPUs yet (though P4 helps).
        \item \textbf{Complex Debugging}: Inspecting code running inside a NIC is harder than on a host.
        \item \textbf{Power Consumption}: High-end DPUs can consume over 75W-100W per card.
    \end{itemize}
\end{frame}

\begin{frame}{Key Takeaways}
    \begin{itemize}
        \item \textbf{Offload is Mandatory}: At 100G+ speeds, host processing is no longer viable.
        \item \textbf{Isolation is Security}: DPUs create a "Hard Gap" between the user VM and the infrastructure provider.
        \item \textbf{The New Tier}: DPUs are becoming the third pillar of data center compute alongside CPUs and GPUs.
    \end{itemize}
\end{frame}

\section{Conclusion}
\begin{frame}{Summary}
    \begin{itemize}
        \item DPUs recover "lost" CPU cycles for user applications.
        \item They provide hardware-level security isolation.
        \item Programming models (P4/eBPF) are maturing fast.
    \end{itemize}
    \vfill
    \centering
    \Large \textbf{Thank You!} \\
    \small Questions?
\end{frame}

\section{References}
\begin{frame}{References}
    \begin{itemize}
        \item Packet Pushers -- DPU-based smart interfaces: \\
        \texttt{https://packetpushers.net/blog/dpu-based-smart-interfaces-and-the-future-of-network-functions-and-security-at-the-edge/}
        \item Ubuntu -- Data centre networking \& SmartNICs: \\
        \texttt{https://ubuntu.com/blog/data-centre-networking-smartnics}
        \item Hot Chips -- NVIDIA DPU (Idan Burstein): \\
        \texttt{https://www.hc33.hotchips.org/assets/program/conference/day1/HC2021.NVIDIA.IdanBurstein.v08.norecording.pdf}
        \item Bosshart et al., "P4: programming protocol-independent packet processors," ACM SIGCOMM CCR, 2014.
        \item Hoiland-Jorgensen et al., "The eXpress Data Path (XDP)," CoNEXT 2018.
        \item G. Liu et al., "A Survey of SmartNICs and DPUs," IEEE Communications Surveys \& Tutorials, 2024.
        \item P4 Language Consortium -- \texttt{https://p4.org}
        \item eBPF resources -- \texttt{https://ebpf.io}
    \end{itemize}
\end{frame}

\end{document}
